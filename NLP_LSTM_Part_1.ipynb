{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-LSTM-Part-1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMy49BQG2wZn9a1V9lzJ8j9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SelvamRaju/Natural-Language-Processing-LSTM/blob/main/NLP_LSTM_Part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP-LSTM-Part-1"
      ],
      "metadata": {
        "id": "55hAASOgrFLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Domain : Digital content and entertainment industry"
      ],
      "metadata": {
        "id": "HjHUANAnrKD7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elUGdZa5q7YM"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Conv1D, GlobalMaxPool1D, LSTM, TimeDistributed, Flatten\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import and analyse the data set.\n",
        "Hint: - Use `imdb.load_data()` method\n",
        "- Get train and test set\n",
        "- Take 10000 most frequent words\n"
      ],
      "metadata": {
        "id": "q24umAY-zKRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000, maxlen=300)"
      ],
      "metadata": {
        "id": "FYl0BIzTznjT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWX1WUXDz2Fr",
        "outputId": "8ccbeeb6-2919-4b12-ff80-c9663039a596"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19051,)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr4r0KEmz6Ww",
        "outputId": "ded151cf-2c0d-4f57-e25d-5f6ebecba510"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19450,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l58LCbyz_ef",
        "outputId": "3e18eab1-fbd1-432d-f942-482ed91a83ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd4Gwqvo0CXS",
        "outputId": "036c8257-8504-4479-d52d-d427278baa7c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing unique labels\n",
        "np.unique(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR56G-g-0nj4",
        "outputId": "55a6217e-d838-46a0-a9a6-610ba9b44c65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Max length of seq. in X_train\n",
        "max(len(i) for i in X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vNMtCEI1Ny3",
        "outputId": "07f06aeb-93a1-430c-fe16-ab5859f75df0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "299"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Max length of seq. in X_test\n",
        "max(len(i) for i in X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUGow8-a2Z98",
        "outputId": "0e40420c-f2c3-4a39-de61-ebcd933aa284"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "299"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Perform relevant sequence adding on the data\n"
      ],
      "metadata": {
        "id": "ZIcEIXQszNNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean of X_train data\n",
        "np.mean([len(i) for i in X_train])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywYdnFD53m7h",
        "outputId": "25469db3-99ee-47d4-c2ab-e4c6bd9e1353"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "159.67697233741012"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The maximum length of a review in the data set it 159 and so padding the data to 200"
      ],
      "metadata": {
        "id": "MUuVUgPR4wG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#padding -  200 length\n",
        "X_train_padded = sequence.pad_sequences(X_train, maxlen=200)\n",
        "X_test_padded = sequence.pad_sequences(X_test, maxlen=200)"
      ],
      "metadata": {
        "id": "lJJ4XcA75GFe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Perform following data analysis:\n",
        "\n",
        "  • Print shape of features and labels\n",
        "  \n",
        "  • Print value of any one feature and it's label\n"
      ],
      "metadata": {
        "id": "ANgdn8PIzQCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of reviews in X_train : \", len(X_train))\n",
        "print(\"Number of reviews in X_test  : \", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsxYNgwyzgzz",
        "outputId": "5e899bdb-9bcc-4a17-c88a-fd8877f272d7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews in X_train :  19051\n",
            "Number of reviews in X_test  :  19450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the number of words in random two review as a sample - Note : padded to 200\n",
        "\n",
        "print(\"1st reveiw in dataset\", X_train_padded[0].shape[0])\n",
        "print(\"100th reveiw in dataset\", X_train_padded[99].shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DH8EXUz5u2I",
        "outputId": "8697871d-f0d3-43f6-b3a1-fc788977e67b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st reveiw in dataset 200\n",
            "100th reveiw in dataset 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Value 50th review : \", X_train[49])\n",
        "print(\"Label of 50th review : \", y_train[49])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQo-kujt6qOR",
        "outputId": "4b71dd00-a79c-40ee-c9ed-373ab7378411"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value 50th review :  [1, 13, 286, 1017, 76, 5, 8, 30, 1202, 13, 161, 40, 14, 22, 4, 86, 58, 187, 21, 149, 12, 174, 5, 13, 5372, 15, 45, 1932, 646, 252, 45, 6, 31, 975, 22, 21, 45, 6, 163, 3288, 10, 10, 294, 5618, 15, 12, 100, 30, 128, 398, 5, 12, 100, 30, 13, 104, 14, 22, 69, 4, 986, 8, 30, 6, 120, 4, 350, 61, 3242, 2, 21, 19, 6, 189, 3232, 305, 7, 6, 2408, 1038, 45, 6, 1053, 1434, 19, 43, 6, 227, 53, 487, 12, 100, 30, 6, 356, 4, 362, 26, 9673, 225, 57, 282, 138, 36, 144, 2, 23, 8, 3584, 972, 39, 4, 578, 1007, 12, 62, 28, 77, 87, 8, 67, 68, 649, 2, 13, 124, 45, 6, 212, 21, 45, 117, 3855, 15, 3138, 4, 52, 108, 39, 4, 530, 10, 10, 3584, 765, 9, 210, 253, 5, 1728, 24, 8, 760, 2, 175, 58, 59, 5852, 25, 80, 99, 45, 254, 8, 3296, 6, 22, 54, 4, 293, 109, 9, 38, 1220, 5, 12, 66, 9, 41, 1382, 92, 387, 41, 272, 2418, 25, 83, 536, 15, 442, 49, 432, 7, 2, 73, 59, 9, 21, 442, 6, 327, 31, 4, 432, 7, 415, 1390, 387, 168, 103, 129, 362, 586, 387, 41, 3107, 18, 98, 151, 10, 10, 474, 386, 743, 12, 6, 140, 10, 10, 43, 92, 535, 99, 76, 10, 10, 442, 53, 74, 43, 6, 87, 270, 7, 8255, 442, 82, 35, 1048, 2162, 7, 2977]\n",
            "Label of 50th review :  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Decode the feature value to get original sentence\n"
      ],
      "metadata": {
        "id": "DKJEsulazSg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting word index from IMDB\n",
        "imdb_word_index = imdb.get_word_index()"
      ],
      "metadata": {
        "id": "CkO6PuEI7ag7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_from = 3\n",
        "imdb_word_index = {key:value + index_from for key, value in imdb_word_index.items()}\n",
        "imdb_word_index['the']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6QFdFwXSC5-",
        "outputId": "bfa9109b-dbe2-4aeb-f955-553cd6a5870f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inverted_word = {value: key for key, value in imdb_word_index.items()}\n",
        "[inverted_word[index] for index in X_train[50] if index > index_from]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAUTfEiXSQxh",
        "outputId": "28d45dd2-8590-4f0f-cb4e-32e46f2db905"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['if',\n",
              " \"you're\",\n",
              " 'a',\n",
              " 'fan',\n",
              " 'of',\n",
              " 'film',\n",
              " 'noir',\n",
              " 'and',\n",
              " 'think',\n",
              " 'they',\n",
              " \"don't\",\n",
              " 'make',\n",
              " \"'em\",\n",
              " 'like',\n",
              " 'they',\n",
              " 'used',\n",
              " 'to',\n",
              " 'here',\n",
              " 'is',\n",
              " 'your',\n",
              " 'answer',\n",
              " 'they',\n",
              " 'just',\n",
              " \"don't\",\n",
              " 'make',\n",
              " \"'em\",\n",
              " 'in',\n",
              " 'hollywood',\n",
              " 'anymore',\n",
              " 'we',\n",
              " 'must',\n",
              " 'turn',\n",
              " 'to',\n",
              " 'the',\n",
              " 'french',\n",
              " 'to',\n",
              " 'remember',\n",
              " 'how',\n",
              " 'satisfying',\n",
              " 'subtle',\n",
              " 'and',\n",
              " 'terrific',\n",
              " 'a',\n",
              " 'well',\n",
              " 'made',\n",
              " 'film',\n",
              " 'from',\n",
              " 'that',\n",
              " 'genre',\n",
              " 'can',\n",
              " 'be',\n",
              " 'read',\n",
              " 'my',\n",
              " 'lips',\n",
              " 'is',\n",
              " 'a',\n",
              " 'wonderfully',\n",
              " 'nasty',\n",
              " 'little',\n",
              " 'gift',\n",
              " 'to',\n",
              " 'the',\n",
              " 'faithful',\n",
              " 'from',\n",
              " 'director',\n",
              " 'jacques',\n",
              " 'featuring',\n",
              " 'sharp',\n",
              " 'storytelling',\n",
              " 'and',\n",
              " 'fine',\n",
              " 'performances',\n",
              " 'from',\n",
              " 'and',\n",
              " 'vincent',\n",
              " 'br',\n",
              " 'br',\n",
              " 'the',\n",
              " 'basic',\n",
              " 'plot',\n",
              " 'could',\n",
              " 'have',\n",
              " 'been',\n",
              " 'written',\n",
              " 'in',\n",
              " 'the',\n",
              " \"40's\",\n",
              " 'dumb',\n",
              " 'but',\n",
              " 'appealing',\n",
              " 'ex',\n",
              " 'con',\n",
              " 'and',\n",
              " 'a',\n",
              " 'smart',\n",
              " 'but',\n",
              " 'femme',\n",
              " 'fatale',\n",
              " 'who',\n",
              " 'turns',\n",
              " 'out',\n",
              " 'to',\n",
              " 'be',\n",
              " 'ambitious',\n",
              " 'discover',\n",
              " 'each',\n",
              " 'other',\n",
              " 'while',\n",
              " 'living',\n",
              " 'lives',\n",
              " 'of',\n",
              " 'bleak',\n",
              " 'desperation',\n",
              " 'and',\n",
              " 'longing',\n",
              " 'manipulate',\n",
              " 'each',\n",
              " 'other',\n",
              " 'to',\n",
              " 'meet',\n",
              " 'their',\n",
              " 'own',\n",
              " 'ends',\n",
              " 'develop',\n",
              " 'complex',\n",
              " 'love',\n",
              " 'hate',\n",
              " 'relationship',\n",
              " 'cook',\n",
              " 'up',\n",
              " 'criminal',\n",
              " 'scheme',\n",
              " 'involving',\n",
              " 'heist',\n",
              " 'double',\n",
              " 'crosses',\n",
              " 'close',\n",
              " 'calls',\n",
              " 'and',\n",
              " 'lots',\n",
              " 'of',\n",
              " 'money',\n",
              " 'all',\n",
              " 'action',\n",
              " 'takes',\n",
              " 'place',\n",
              " 'in',\n",
              " 'depressing',\n",
              " 'seedy',\n",
              " 'and',\n",
              " 'or',\n",
              " 'poorly',\n",
              " 'lit',\n",
              " 'locations',\n",
              " 'br',\n",
              " 'br',\n",
              " 'has',\n",
              " 'fashioned',\n",
              " 'some',\n",
              " 'modern',\n",
              " 'twists',\n",
              " 'of',\n",
              " 'course',\n",
              " 'the',\n",
              " 'femme',\n",
              " 'fatale',\n",
              " 'is',\n",
              " 'an',\n",
              " 'office',\n",
              " 'worker',\n",
              " 'who',\n",
              " 'happens',\n",
              " 'to',\n",
              " 'be',\n",
              " 'nearly',\n",
              " 'deaf',\n",
              " 'and',\n",
              " 'uses',\n",
              " 'her',\n",
              " 'lip',\n",
              " 'reading',\n",
              " 'ability',\n",
              " 'to',\n",
              " 'take',\n",
              " 'revenge',\n",
              " 'on',\n",
              " 'those',\n",
              " 'who',\n",
              " 'her',\n",
              " 'and',\n",
              " 'where',\n",
              " 'you',\n",
              " 'might',\n",
              " 'expect',\n",
              " 'steamy',\n",
              " 'love',\n",
              " 'scenes',\n",
              " 'you',\n",
              " 'discover',\n",
              " 'that',\n",
              " 'both',\n",
              " 'characters',\n",
              " 'are',\n",
              " 'sexually',\n",
              " 'awkward',\n",
              " 'and',\n",
              " 'immature',\n",
              " 'add',\n",
              " 'in',\n",
              " 'a',\n",
              " 'bit',\n",
              " 'of',\n",
              " 'modern',\n",
              " 'technology',\n",
              " 'and',\n",
              " 'music',\n",
              " 'and',\n",
              " 'it',\n",
              " 'seems',\n",
              " 'like',\n",
              " 'a',\n",
              " 'contemporary',\n",
              " 'film',\n",
              " 'but',\n",
              " 'make',\n",
              " 'no',\n",
              " 'mistake',\n",
              " 'this',\n",
              " 'is',\n",
              " 'old',\n",
              " 'school',\n",
              " 'film',\n",
              " 'noir',\n",
              " \"it's\",\n",
              " 'as',\n",
              " 'good',\n",
              " 'as',\n",
              " 'any',\n",
              " 'film',\n",
              " 'from',\n",
              " 'the',\n",
              " 'genre',\n",
              " 'and',\n",
              " 'easily',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'best',\n",
              " 'films',\n",
              " \"i've\",\n",
              " 'seen',\n",
              " 'all',\n",
              " 'year']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  Result 1 for Positive Review\n",
        "*  Result 2 for Negative Review"
      ],
      "metadata": {
        "id": "Y4yJoTMgTX7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzBKlAECTOQ5",
        "outputId": "7d533e9c-d0be-4408-e9d3-31caca1006f9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Review @ 50th in the data is Postive"
      ],
      "metadata": {
        "id": "UADIyCFCTqjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Design, train, tune and test a sequential model.\n",
        "\n",
        "  Hint: The aim here Is to import the text, process it such a way that it can be taken as an inout to the ML/NN\n",
        "classifiers. Be analytical and experimental here in trying new approaches to design the best model.\n"
      ],
      "metadata": {
        "id": "9-2SC5xYzUzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = 10000\n",
        "max_words = 200\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary, 100, input_length=max_words))\n",
        "model.add(LSTM(100,return_sequences= True))\n",
        "dense_layer = Dense(100, activation='relu')\n",
        "model.add(TimeDistributed(dense_layer))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "uUs1A7pzTzYo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "g-EltTTNUWiy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYkJKomvUb2P",
        "outputId": "4d8c6b27-42cd-4980-9e85-466a9776e0df"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 100)          1000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 200, 100)          80400     \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 200, 100)         10100     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 20000)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 20001     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,110,501\n",
            "Trainable params: 1,110,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Fitting\n",
        "model.fit(X_train_padded, y_train, epochs=5, batch_size=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6Q7KL_ZUhnQ",
        "outputId": "c67243ce-d040-48cc-cb2c-ff3171b1bcd2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "382/382 [==============================] - 99s 252ms/step - loss: 0.3634 - accuracy: 0.8258\n",
            "Epoch 2/5\n",
            "382/382 [==============================] - 95s 248ms/step - loss: 0.1778 - accuracy: 0.9332\n",
            "Epoch 3/5\n",
            "382/382 [==============================] - 96s 252ms/step - loss: 0.0983 - accuracy: 0.9637\n",
            "Epoch 4/5\n",
            "382/382 [==============================] - 96s 253ms/step - loss: 0.0611 - accuracy: 0.9786\n",
            "Epoch 5/5\n",
            "382/382 [==============================] - 94s 247ms/step - loss: 0.0386 - accuracy: 0.9856\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2f9cebefd0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing scores and accuracy\n",
        "scores, accuracy = model.evaluate(X_test_padded, y_test, verbose=0)\n",
        "print(\"Score :\", scores)\n",
        "print(\"Accuracy :\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znwg2POnWTZQ",
        "outputId": "b1e5a91c-e213-46f6-b34a-91dc085e96e4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score : 0.6416922211647034\n",
            "Accuracy : 0.8547557592391968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Use the designed model to print the prediction on any one sample."
      ],
      "metadata": {
        "id": "W8Rd2a9IzWyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positiveReview = \"i liked this wonderful movie\"\n",
        "negatvieReview = \"i did not like this awkward movie\""
      ],
      "metadata": {
        "id": "PvAA1btxWnE6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for review in [positiveReview, negatvieReview]:\n",
        "    encoded_review = []\n",
        "    review_split = review.split(\" \")\n",
        "    for word in review_split:\n",
        "        encoded_review.append(imdb_word_index[word])\n",
        "    review_padded = pad_sequences([encoded_review], maxlen=200)\n",
        "    pred = model.predict(review_padded)\n",
        "    if pred > 0.5:\n",
        "        typeOfReview = 'Positive Review'\n",
        "    else:\n",
        "        typeOfReview = 'Negative Review'\n",
        "    print(\"Review : \", review)\n",
        "    print(\"Type of Review : \", typeOfReview)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh3bURrKW-Ew",
        "outputId": "da1a9a4c-67ed-472b-ca1f-f498b398fd67"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review :  i liked this wonderful movie\n",
            "Type of Review :  Positive Review\n",
            "Review :  i did not like this awkward movie\n",
            "Type of Review :  Negative Review\n"
          ]
        }
      ]
    }
  ]
}